{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from datasets import DateDataset\n",
    "from model import FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, optimizer, loss_fn, train_loader, val_loader, epochs, save_path):\n",
    "    train_losses = [None] * epochs\n",
    "    val_losses = [None] * epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for x_batch,y_batch in train_loader:\n",
    "            x_batch = x_batch.float()\n",
    "            predictions = model(x_batch)\n",
    "        \n",
    "            loss = loss_fn(predictions, y_batch.long())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            \n",
    "            _, class_prediction = torch.max(predictions, dim=1)\n",
    "            train_correct += (class_prediction == y_batch).sum().item()\n",
    "            train_total += y_batch.shape[0]\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        for x_batch,y_batch in val_loader:\n",
    "            x_batch = x_batch.float()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                predictions = model(x_batch)\n",
    "                loss = loss_fn(predictions, y_batch.long())\n",
    "\n",
    "                _, class_prediction = torch.max(predictions, dim=1)\n",
    "                val_correct += (class_prediction == y_batch).sum().item()\n",
    "\n",
    "                val_total += y_batch.shape[0]\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_loss /= train_total\n",
    "        train_losses[epoch] = train_loss\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= val_total\n",
    "        val_losses[epoch] = val_loss\n",
    "        \n",
    "        print(f'Epoch {epoch+1:<2} / {epochs}: Train Loss: {train_loss:.2f}  Train Accuracy: {train_accuracy*100:.2f}%  Validation Loss: {val_loss:.2f} Validaton Accuracy: {val_accuracy*100:.2f}%')\n",
    "    \n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  / 10: Train Loss: 0.01  Train Accuracy: 59.33%  Validation Loss: 0.01 Validaton Accuracy: 82.78%\n",
      "Epoch 2  / 10: Train Loss: 0.00  Train Accuracy: 84.12%  Validation Loss: 0.00 Validaton Accuracy: 86.67%\n",
      "Epoch 3  / 10: Train Loss: 0.00  Train Accuracy: 89.14%  Validation Loss: 0.00 Validaton Accuracy: 91.11%\n",
      "Epoch 4  / 10: Train Loss: 0.00  Train Accuracy: 92.06%  Validation Loss: 0.00 Validaton Accuracy: 90.56%\n",
      "Epoch 5  / 10: Train Loss: 0.00  Train Accuracy: 94.15%  Validation Loss: 0.00 Validaton Accuracy: 93.33%\n",
      "Epoch 6  / 10: Train Loss: 0.00  Train Accuracy: 94.99%  Validation Loss: 0.00 Validaton Accuracy: 93.33%\n",
      "Epoch 7  / 10: Train Loss: 0.00  Train Accuracy: 95.40%  Validation Loss: 0.00 Validaton Accuracy: 93.33%\n",
      "Epoch 8  / 10: Train Loss: 0.00  Train Accuracy: 96.80%  Validation Loss: 0.00 Validaton Accuracy: 91.67%\n",
      "Epoch 9  / 10: Train Loss: 0.00  Train Accuracy: 97.08%  Validation Loss: 0.00 Validaton Accuracy: 93.89%\n",
      "Epoch 10 / 10: Train Loss: 0.00  Train Accuracy: 97.77%  Validation Loss: 0.00 Validaton Accuracy: 93.89%\n"
     ]
    }
   ],
   "source": [
    "in_features = 34\n",
    "out_features = 34\n",
    "n_classes = 7\n",
    "f_name = None\n",
    "model = FeatureExtractor((in_features, 1024, 1024, out_features, n_classes), torch.nn.functional.relu)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_data = DateDataset('date-data/train.csv')\n",
    "val_data = DateDataset('date-data/test.csv')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=False, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=128, shuffle=False, pin_memory=True)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "model = train_classifier(model, optimizer, loss_fn, train_loader, val_loader, epochs, f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = FeatureExtractor((in_features, 1024, 7), torch.nn.functional.relu)\n",
    "# model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Raw Features with end to end NN classifier\n",
    "Since we trained the NN classifier in the previous step using the train data this step will evaluate the classification accuracy on the test/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 93.89%\n",
      "F1 Score: 0.9373\n"
     ]
    }
   ],
   "source": [
    "m = len(val_data)\n",
    "y_true = np.zeros(m)\n",
    "y_pred = np.zeros(m)\n",
    "\n",
    "for i in range(m):\n",
    "    x,y = val_data[i]\n",
    "    prediction = model(torch.from_numpy(x))\n",
    "    # get index of class w/ max prob and set its value to be y_pred[i]\n",
    "    y_pred[i] = torch.argmax(prediction).item()\n",
    "    y_true[i] = y\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, labels=[0,1,2,3,4,5,6], average=\"weighted\")\n",
    "\n",
    "print(f'Accuracy {acc * 100:.2f}%')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) & 3) Raw Features with SVM Classifier (Linear & RBF Kernel)\n",
    "\n",
    "In this step we will train the linear SVM using the train set and then evaluate its classification accuracy on the test/validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Accuracy: 93.33%\n",
      "Linear F1 Score: 0.9314\n",
      "RBF Accuracy: 92.78%\n",
      "RBF F1 Score: 0.9243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train\n",
    "train_data = np.genfromtxt('date-data/train.csv', delimiter=',', skip_header=1)\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "\n",
    "\n",
    "# Test\n",
    "test_data = np.genfromtxt('date-data/test.csv', delimiter=',', skip_header=1)\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "\n",
    "\n",
    "linear_svm = SVC(kernel=\"linear\", C =10).fit(X_train, y_train)\n",
    "rbf_svm = SVC(kernel=\"rbf\", C=10).fit(X_train, y_train)\n",
    "\n",
    "linear_pred = linear_svm.predict(X_test)\n",
    "rbf_pred = rbf_svm.predict(X_test)\n",
    "\n",
    "linear_acc = accuracy_score(y_test, linear_pred)\n",
    "rbf_acc = accuracy_score(y_test, rbf_pred)\n",
    "linear_f1 = f1_score(y_test, linear_pred, labels=[0,1,2,3,4,5,6], average=\"weighted\")\n",
    "rbf_f1 = f1_score(y_test, rbf_pred, labels=[0,1,2,3,4,5,6], average=\"weighted\")\n",
    "\n",
    "print(f'Linear Accuracy: {linear_acc * 100:.2f}%')\n",
    "print(f'Linear F1 Score: {linear_f1:.4f}')\n",
    "print(f'RBF Accuracy: {rbf_acc * 100:.2f}%')\n",
    "print(f'RBF F1 Score: {rbf_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) & 5) NN Extracted Features with SVM Classifier (Linear & RBF Kernel)\n",
    "\n",
    "We will construct a training dataset by running the train set through the neural network set to extract features. We will then train the SVMs on this dataset. We will then construct a test dataset by running the test set through the neural network to extract new features. We will then evaluate the classification accuracy of the SVMs on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Accuracy: 95.56%\n",
      "Linear F1 Score: 0.9541\n",
      "RBF Accuracy: 92.22%\n",
      "RBF F1 Score: 0.9192\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros((len(train_data),out_features))\n",
    "y_train = np.zeros(len(train_data))\n",
    "\n",
    "X_test = np.zeros((len(val_data),out_features))\n",
    "y_test = np.zeros(len(val_data))\n",
    "\n",
    "model.set_extract_feature_mode(True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for x,y in train_loader:\n",
    "        predictions = model(x.float()).numpy()\n",
    "        \n",
    "        for r in range(predictions.shape[0]):\n",
    "            X_train[i, :] = predictions[r,:]\n",
    "            y_train[i] = y[r]\n",
    "            i += 1\n",
    "\n",
    "linear_svm = SVC(kernel=\"linear\").fit(X_train, y_train)\n",
    "rbf_svm = SVC(kernel=\"rbf\").fit(X_train, y_train)\n",
    "\n",
    "with torch.no_grad():\n",
    "    i = 0\n",
    "    for x,y in val_loader:\n",
    "        predictions = model(x.float()).numpy()\n",
    "\n",
    "        for r in range(predictions.shape[0]):\n",
    "            X_test[i,:] = predictions[r,:]\n",
    "            y_test[i] = y[r]\n",
    "            i += 1\n",
    "\n",
    "linear_acc = linear_svm.score(X_test, y_test)\n",
    "rbf_acc = rbf_svm.score(X_test, y_test)\n",
    "\n",
    "linear_pred = linear_svm.predict(X_test)\n",
    "rbf_pred = rbf_svm.predict(X_test)\n",
    "\n",
    "linear_f1 = f1_score(y_test, linear_pred, labels=[0,1,2,3,4,5,6], average=\"weighted\")\n",
    "rbf_f1 = f1_score(y_test, rbf_pred, labels=[0,1,2,3,4,5,6], average=\"weighted\")\n",
    "\n",
    "print(f'Linear Accuracy: {linear_acc * 100:.2f}%')\n",
    "print(f'Linear F1 Score: {linear_f1:.4f}')\n",
    "print(f'RBF Accuracy: {rbf_acc * 100:.2f}%')\n",
    "print(f'RBF F1 Score: {rbf_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) & 7) PCA Extracted Features with SVM Classifier (Linear & RBF Kernel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Linear Accuracy: 93.33%\n",
      "PCA Linear F1 Score: 0.9321\n",
      "PCA RBF Accuracy: 92.78%\n",
      "PCA RBF F1 Score: 0.9243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Train\n",
    "train_data = np.genfromtxt('date-data/train.csv', delimiter=',', skip_header=1)\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "pca = pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "\n",
    "# Test\n",
    "test_data = np.genfromtxt('date-data/test.csv', delimiter=',', skip_header=1)\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "linear_svm = SVC(kernel=\"linear\", C=10).fit(X_train, y_train)\n",
    "rbf_svm = SVC(kernel=\"rbf\", C=10).fit(X_train, y_train)\n",
    "\n",
    "linear_pred = linear_svm.predict(X_test)\n",
    "rbf_pred = rbf_svm.predict(X_test)\n",
    "\n",
    "linear_acc = accuracy_score(y_test, linear_pred)\n",
    "rbf_acc = accuracy_score(y_test, rbf_pred)\n",
    "linear_f1 = f1_score(y_test, linear_pred, labels=[0,1,2,3,4,5,6], average=\"weighted\")\n",
    "rbf_f1 = f1_score(y_test, rbf_pred, labels=[0,1,2,3,4,5,6], average=\"weighted\")\n",
    "\n",
    "print(f'PCA Linear Accuracy: {linear_acc * 100:.2f}%')\n",
    "print(f'PCA Linear F1 Score: {linear_f1:.4f}')\n",
    "print(f'PCA RBF Accuracy: {rbf_acc * 100:.2f}%')\n",
    "print(f'PCA RBF F1 Score: {rbf_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  / 10: Train Loss: 0.01  Train Accuracy: 60.72%  Validation Loss: 0.01 Validaton Accuracy: 82.78%\n",
      "Epoch 2  / 10: Train Loss: 0.00  Train Accuracy: 87.19%  Validation Loss: 0.01 Validaton Accuracy: 85.56%\n",
      "Epoch 3  / 10: Train Loss: 0.00  Train Accuracy: 89.69%  Validation Loss: 0.00 Validaton Accuracy: 87.78%\n",
      "Epoch 4  / 10: Train Loss: 0.00  Train Accuracy: 92.48%  Validation Loss: 0.00 Validaton Accuracy: 89.44%\n",
      "Epoch 5  / 10: Train Loss: 0.00  Train Accuracy: 94.71%  Validation Loss: 0.00 Validaton Accuracy: 90.00%\n",
      "Epoch 6  / 10: Train Loss: 0.00  Train Accuracy: 95.68%  Validation Loss: 0.00 Validaton Accuracy: 92.22%\n",
      "Epoch 7  / 10: Train Loss: 0.00  Train Accuracy: 96.94%  Validation Loss: 0.00 Validaton Accuracy: 92.78%\n",
      "Epoch 8  / 10: Train Loss: 0.00  Train Accuracy: 97.63%  Validation Loss: 0.00 Validaton Accuracy: 92.78%\n",
      "Epoch 9  / 10: Train Loss: 0.00  Train Accuracy: 98.05%  Validation Loss: 0.00 Validaton Accuracy: 92.78%\n",
      "Epoch 10 / 10: Train Loss: 0.00  Train Accuracy: 98.47%  Validation Loss: 0.00 Validaton Accuracy: 94.44%\n",
      "PCA Features NN Accuracy 94.44%\n",
      "PCA FEatures NN F1 Score: 0.9437\n"
     ]
    }
   ],
   "source": [
    "in_features = 20\n",
    "n_classes = 7\n",
    "model = FeatureExtractor((in_features, 1024, 1024, n_classes), torch.nn.functional.relu)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_data = DateDataset('date-data/train.csv')\n",
    "train_data.data = np.hstack((X_train, np.expand_dims(y_train, axis=1)))\n",
    "val_data = DateDataset('date-data/test.csv')\n",
    "val_data.data = np.hstack((X_test, np.expand_dims(y_test, axis=1)))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=False, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=128, shuffle=False, pin_memory=True)\n",
    "\n",
    "epochs = 10\n",
    "model = train_classifier(model, optimizer, loss_fn, train_loader, val_loader, epochs, 'pca-1024-1024.pt')\n",
    "\n",
    "m = len(val_data)\n",
    "y_true = np.zeros(m)\n",
    "y_pred = np.zeros(m)\n",
    "\n",
    "for i in range(m):\n",
    "    x,y = val_data[i]\n",
    "    prediction = model(torch.from_numpy(x.astype(np.float32)))\n",
    "    # get index of class w/ max prob and set its value to be y_pred[i]\n",
    "    y_pred[i] = torch.argmax(prediction).item()\n",
    "    y_true[i] = y\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, labels=[0,1,2,3,4,5,6], average=\"weighted\")\n",
    "\n",
    "print(f'PCA Features NN Accuracy {acc * 100:.2f}%')\n",
    "print(f'PCA FEatures NN F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "780a2c011053422c520cbf422b565c1ced2a7536a2b28a02cb3d3d7e7e53add8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('project_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
