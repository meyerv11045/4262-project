{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from datasets import DateDataset\n",
    "from model import FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, optimizer, loss_fn, train_loader, val_loader, epochs, save_path):\n",
    "    train_losses = [None] * epochs\n",
    "    val_losses = [None] * epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for x_batch,y_batch in train_loader:\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_batch.float()\n",
    "\n",
    "            predictions = model(x_batch)\n",
    "            _, predicted = torch.max(predictions.data)\n",
    "            predicted = predicted.long()            \n",
    "        \n",
    "            loss = loss_fn(predicted, y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            \n",
    "            train_correct += (predicted == y_batch).sum().item()\n",
    "            train_total += y_batch.shape[0]\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        for x_batch,y_batch in val_loader:\n",
    "            x_batch = x_batch.float()\n",
    "            y_batch = y_batch.float()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                predictions = model(x_batch)\n",
    "                _, predicted = torch.max(predictions.data)\n",
    "                predicted = predicted.long()\n",
    "\n",
    "                loss = loss_fn(predicted, y_batch)\n",
    "                val_correct += (predicted == y_batch).sum().item()\n",
    "                val_total += y_batch.shape[0]\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_loss /= train_total\n",
    "        train_losses[epoch] = train_loss\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= val_total\n",
    "        val_losses[epoch] = val_loss\n",
    "        \n",
    "        print(f'Epoch {epoch+1:<2} / {epochs}: Train Loss: {train_loss:.2f}  Train Accuracy: {train_accuracy*100:.2f}%  Validation Loss: {val_loss:.2f} Validaton Accuracy: {val_accuracy*100:.2f}%')\n",
    "\n",
    "    torch.save(model.parameters(), save_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Linear(in_features=34, out_features=1024, bias=True)\n",
      "  (1): Linear(in_features=1024, out_features=34, bias=True)\n",
      "  (2): Linear(in_features=34, out_features=7, bias=True)\n",
      ")\n",
      "Linear(in_features=34, out_features=1024, bias=True)\n",
      "Linear(in_features=1024, out_features=34, bias=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (Tensor, keepdim=bool), but expected one of:\n * (Tensor input)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/vikram/CS4262/project/experiment.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vikram/CS4262/project/experiment.ipynb#ch0000002?line=10'>11</a>\u001b[0m val_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(val_data, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, pin_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vikram/CS4262/project/experiment.ipynb#ch0000002?line=12'>13</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vikram/CS4262/project/experiment.ipynb#ch0000002?line=14'>15</a>\u001b[0m model \u001b[39m=\u001b[39m train_classifier(model, optimizer, loss_fn, train_loader, val_loader, epochs, \u001b[39m'\u001b[39;49m\u001b[39mmodel.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/vikram/CS4262/project/experiment.ipynb Cell 2'\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(model, optimizer, loss_fn, train_loader, val_loader, epochs, save_path)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vikram/CS4262/project/experiment.ipynb#ch0000001?line=13'>14</a>\u001b[0m y_batch \u001b[39m=\u001b[39m y_batch\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vikram/CS4262/project/experiment.ipynb#ch0000001?line=15'>16</a>\u001b[0m predictions \u001b[39m=\u001b[39m model(x_batch)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vikram/CS4262/project/experiment.ipynb#ch0000001?line=16'>17</a>\u001b[0m _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmax(predictions\u001b[39m.\u001b[39;49mdata, keepdim\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vikram/CS4262/project/experiment.ipynb#ch0000001?line=17'>18</a>\u001b[0m predicted \u001b[39m=\u001b[39m predicted\u001b[39m.\u001b[39mlong()            \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vikram/CS4262/project/experiment.ipynb#ch0000001?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(predicted, y_batch)\n",
      "\u001b[0;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (Tensor, keepdim=bool), but expected one of:\n * (Tensor input)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "in_features = 34\n",
    "n_classes = 7\n",
    "model = FeatureExtractor((in_features, 1024, in_features, n_classes), torch.nn.functional.relu)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_data = DateDataset('date-data/train.csv')\n",
    "val_data = DateDataset('date-data/test.csv')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=False, pin_memory=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=128, shuffle=False, pin_memory=True)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "model = train_classifier(model, optimizer, loss_fn, train_loader, val_loader, epochs, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Raw Features with end to end NN classifier\n",
    "Since we trained the NN classifier in the previous step using the train data this step will evaluate the classification accuracy on the test/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(val_data)\n",
    "y_true = np.zeros(m)\n",
    "y_pred = np.zeros(m)\n",
    "\n",
    "for i in range(m):\n",
    "    x,y = val_data[i]\n",
    "    prediction = model(torch.from_numpy(x))\n",
    "    # get index of class w/ max prob and set its value to be y_pred[i]\n",
    "    y_pred[i] = torch.argmax(prediction).item()\n",
    "    \n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, labels=[0,1,2,3,4,5,6], average=\"weighted\")\n",
    "\n",
    "print(f'Accuracy {acc * 100:.2f}%')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) & 3) Raw Features with SVM Classifier (Linear & RBF Kernel)\n",
    "\n",
    "In this step we will train the linear SVM using the train set and then evaluate its classification accuracy on the test/validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train\n",
    "train_data = np.genfromtxt('date-data/train.csv')\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "\n",
    "\n",
    "# Test\n",
    "test_data = np.genfromtxt('date-data/test.csv')\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "\n",
    "linear_svm = SVC(kernel=\"linear\").fit(X_train, y_train)\n",
    "rbf_svm = SVC(kernel=\"rbf\").fit(X_train, y_train)\n",
    "\n",
    "linear_acc = linear_svm.score(X_test, y_test)\n",
    "rbf_acc = rbf_svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) & 5) NN Extracted Features with SVM Classifier (Linear & RBF Kernel)\n",
    "\n",
    "We will construct a training dataset by running the train set through the neural network set to extract features. We will then train the SVMs on this dataset. We will then construct a test dataset by running the test set through the neural network to extract new features. We will then evaluate the classification accuracy of the SVMs on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "780a2c011053422c520cbf422b565c1ced2a7536a2b28a02cb3d3d7e7e53add8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('project_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
